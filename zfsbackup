#!/bin/sh -e

# zfs filesystems/snapshots allow space in their name but not tab or newline
OLD_IFS=$IFS
IFS=$(printf '\n\t')

PATH=$PATH:/usr/sbin

usage() {
    echo "\
usage: $0 [-vn] dataset target [target_host]
    -v  be verbose (passes -P to zfs send)
    -n  dry-run mode (passed to zfs send)

'dataset' and all its descendants (including all existing snapshots) will be
backed up under dataset 'target/POOLNAME' [on target_host using ssh] where
POOLNAME is derived from 'dataset'.

The dataset 'target/POOLNAME' should exist [on target_host] and should have
readonly=on, as well as appropriate permission delegations (see below).

The running user should have ssh configuration set up properly and must have
permission to use the following zfs commands:
 - create,hold,mount,receive,release,rename,userprop on the target host
   - property permissions such as
     aclmode,aclinherit,quota,refquota,sharenfs,compression are also required, at
     least until https://www.illumos.org/issues/3753 is fixed
 - hold,release,send on the local host
without sudo/pfexec (use zfs allow)." >&2
}

set -u

dryrun=false
nflg=
vflg=
while getopts nv flag; do
    case $flag in
        n) dryrun=true; nflg="-n";;
        v) verbose=true; vflg="-P";;
        ?) usage; exit 1;;
    esac
done

shift $((OPTIND - 1))

set +u
dataset="$1"
target="$2"
targetmachine="$3"
set -u

HOLD_TAG=niksula:zfsbackup

[ -z "$dataset" -o -z "$target" ] && { usage; exit 1; }

cleanup() {
    # We can recover from partially sent incrementals on next run, but if this
    # was a partially sent full backup, next run will have no consistent
    # incremental source. Since we would have to send the entire dataset again
    # anyway, there's little point in trying to recover.
    if ! $incremental; then
        echo "\
Full backup failed (possibly partially). Remove the target dataset
    ${target}/${dataset}
before retrying." >&2
        zfs release -r $HOLD_TAG $last
    else
        echo "\
Incremental backup failed (possibly partially). Recovery will be attempted on
next run by sending all intermediate snapshots after this failed run's
incremental source
    $from
Keeping local holds on:
    ${dataset}@${fromsnap}
    $last
- the latter can be manually released after successful recovery run." >&2
    fi
    exit 1
}

die() {
    echo "$@" >&2
    if $incremental && [ -n $last ]; then
        zfs release -r "$HOLD_TAG" "$last"
    fi
    exit 1
}

print_tagged() {
    awk '$2 == "'"$HOLD_TAG"'" { print $1 }'
}

on_target() {
    if [ -z "$targetmachine" ]; then
        "$@"
    else
        ssh "$targetmachine" "$@"
    fi
}

pool=${dataset%%/*}
[ -z "$pool" ] && { echo "fatal: unable to determine pool name from $dataset" >&2; exit 1; }

incremental=true

local_snaplist=$(zfs list -Ho name -S creation -t snapshot -d 1 $dataset) || { echo "fatal: could not get local dataset list" >&2; exit 1; }
# getting remote snapshot list can fail with exit 1 if the dataset does not
# exist on the target
if remote_snaplist=$(on_target zfs list -Ho name,userrefs -S creation -t snapshot -d 1 ${target}/${dataset}); then
    # we can't negate the if condition here because that will affect $?, so
    # this is required
    :
else
    status=$?
    if [ $status -eq 1 ]; then
        remote_snaplist=
    else
        # something else went wrong (perhaps the ssh connection failed); bail
        echo "fatal: could not get remote snapshot list (exit status $status)" >&2
        exit 1
    fi
fi
# if remote_snaplist is empty here, either target has no snapshots, or the
# dataset doesn't exist, so send a full backup.
[ -z "$remote_snaplist" ] && incremental=false

# list is sorted by creation date, return the first matching snap
last=$(echo "$local_snaplist" | head -1)
lastsnap="${last#*@}"
if [ -z "$last" ]; then
    echo "\
fatal: cannot get latest local snapshot of $dataset; are there any?" >&2
    exit 1
fi

# zfs hold fails if tag already exists, so check for it
if [ -z "$(zfs holds -H "$last" | print_tagged)" ]; then
    zfs hold -r "$HOLD_TAG" "$last"
fi
trap cleanup INT HUP TERM
if $incremental; then
    remote_latest=$(echo "$remote_snaplist" | head -1 | cut -f1)
    # The incremental source should be the latest snapshot on the remote side
    # which has a hold with our tag.
    remote_held=$(echo "$remote_snaplist" | awk '$2 != 0 { print $1 }')
    # Ask for holds on all snapshots with userrefs > 0 and get the first that
    # has our tag.
    if [ -z "$remote_held" ]; then
        die "fatal: remote has snapshots, but none are held"
    fi
    # NOTE: zfs holds seems to sort its output instead of printing lines in
    # input order. TODO figure out what key it sorts on and why
    tagged=$(echo "$remote_held" | on_target xargs zfs holds -H | print_tagged)
    from=$(echo "$tagged" | tail -1)
    if [ -z "$from" ]; then
        die "\
fatal: failed to determine incremental source from existing remote
snapshots (must be held with '$HOLD_TAG')"
    fi
    fromsnap="${from#*@}"
    if [ "$fromsnap" = "$lastsnap" ]; then
        die "fatal: incremental source $fromsnap and $last are the same"
    fi
    # by default, don't send intermediary snapshots
    iflag="-i"
    # https://www.illumos.org/issues/4718
    if ! zfs list -Ho name "${dataset}@${fromsnap}" >/dev/null 2>&1; then
        die "\
fatal: local incremental source
    ${dataset}@${fromsnap}
does not exist. Manual intervention required."
    fi
    if [ -z "$(zfs holds -H "${dataset}@${fromsnap}" | print_tagged)" ]; then
        echo "\
W: local incremental source
    ${dataset}@${fromsnap}
is not held; holding it and sending incremental anyway" >&2
        zfs hold -r $HOLD_TAG "${dataset}@${fromsnap}"
    fi
    if [ "$from" != "$remote_latest" ]; then
        # remote has more recent snapshots than the incremental source;
        # something is wrong. Either the previous send was incomplete (only
        # some datasets' snapshots were sent), or something else has modified
        # the target's snapshots. We can't really distinguish between these
        # cases before actually trying the send, but we can recover from the
        # first by either retrying the send with the same snapshot arguments as
        # before (which would stagger backing up our latest data), or sending
        # intermediary snapshots as well (which works, but is a bit slower).
        echo "\
W: newest remote snapshot
    $remote_latest
does not have the hold tag '${HOLD_TAG}'. Recovery may succeed if this
discrepancy was caused by the previous send completing partially. Attempting
recovery by sending intermediate snapshots between
    $fromsnap
    and ${last}" >&2
        iflag="-I"
    fi
    # NOTE: don't use -F with recv here, since that will prune snapshots from
    # the receiver side (and thus requires destroy permissions there). Instead
    # the receiving dataset should be readonly=on to keep it from getting
    # modified between backups.
    zfs send $nflg $vflg -R $iflag "$fromsnap" "$last" | on_target zfs recv -ud "${target}/${pool}" || {
        if $dryrun; then
            echo "dry run; ignoring recv failure." >&2
        else
            echo "E: incremental backup '${last}' failed, cleaning up...'" >&2
            cleanup
        fi
    }
else
    echo "W: sending full $last" >&2
    # NOTE: we should *NOT* use recv -F here because it is potentially
    # destructive!
    zfs send $nflg $vflg -R "$last" | on_target zfs recv -ud "${target}/${pool}" || {
        if $dryrun; then
            echo "dry run; ignoring recv failure." >&2
        else
            echo "E: full backup '${last}' failed, cleaning up..." >&2
            cleanup
        fi
    }
fi
trap '' INT TERM HUP
# Backup success, create new holds and release possible old ones. We
# already have a hold on the local side, need to create one on the remote
# side
# NB: hold seems to succeed on non-existing snapshots so check for that!
if ! $dryrun; then
    on_target "zfs list -Ho name '${target}/$last' >/dev/null && zfs hold -r $HOLD_TAG '${target}/${last}'" || die "\
E: backup success, but failed to hold remote snapshot
    ${target}/${last}
Data may be resent on the next run or it may fail entirely."
    if $incremental; then
        zfs release -r $HOLD_TAG "${dataset}@${fromsnap}" || echo "W: local release of ${dataset}@${fromsnap} failed" >&2
        on_target zfs release -r $HOLD_TAG "$from"
    fi
fi
