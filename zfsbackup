#!/bin/sh -e

# zfs filesystems/snapshots allow space in their name but not tab or newline
OLD_IFS=$IFS
IFS=$(printf '\n\t')

PATH=$PATH:/usr/sbin

usage() {
    echo "\
usage: $0 dataset target [target_host]

'dataset' and all its descendants (including all existing snapshots) will be
backed up under dataset 'target/POOLNAME' [on target_host using ssh] where
POOLNAME is derived from 'dataset'.

The dataset 'target/POOLNAME' should exist [on target_host] and should have
readonly=on, as well as appropriate permission delegations (see below).

The running user should have ssh configuration set up properly and must have
permission to use the following zfs commands:
 - create,hold,mount,receive,release,rename,userprop on the target host
   - property permissions such as
     aclmode,aclinherit,quota,refquota,sharenfs,compression are also required, at
     least until https://www.illumos.org/issues/3753 is fixed
 - hold,release,send on the local host
without sudo/pfexec (use zfs allow)." >&2
}

dataset="$1"
target="$2"
targetmachine="$3"

set -u

HOLD_TAG=niksula:zfsbackup

[ -z "$dataset" -o -z "$target" ] && { usage; exit 1; }

cleanup() {
    if [ -n "$last" ]; then
        zfs release -r $HOLD_TAG $last
        # If we did a partial send (not all descendant filesystems), we must
        # destroy the sent snapshots on the target host or the next send will
        # fail due to some datasets' most recent snapshot not matching the
        # incremental source. We might not have destroy permissions on the
        # target host, though, so output an error if this fails.
        if ! on_target zfs destroy -r "${target}/${last}"; then
            echo "ACTION REQUIRED: 'zfs destroy -r ${target}/${last}' on"\
                "${targetmachine:-localhost} or next backup run may fail" >&2
        fi
    fi
    exit 1
}

on_target() {
    if [ -z "$targetmachine" ]; then
        "$@"
    else
        ssh "$targetmachine" "$@"
    fi
}

pool=${dataset%%/*}
[ -z "$pool" ] && { echo "fatal: unable to determine pool name from $dataset" >&2; exit 1; }

local_snaplist=$(zfs list -Ho name -S creation -t snapshot -d 1 $dataset) || { echo "fatal: could not get local dataset list" >&2; exit 1; }
# getting remote snapshot list can fail if the dataset does not exist on the
# target
remote_snaplist=$(on_target zfs list -Ho name -S creation -t snapshot -d 1 ${target}/${dataset}) || true

# list is sorted by creation date, return the first matching snap
last=$(echo "$local_snaplist" | head -1)
lastsnap=${last#*@}
if [ -z "$last" ]; then
    # no snapshots apparently
    echo "fatal: cannot get latest snapshot" >&2
fi

# don't die if tag already exists
zfs hold -r $HOLD_TAG $last || true
trap cleanup INT HUP TERM
# what's the incremental source, ie. latest snapshot the receiving side has?
from=$(echo "$remote_snaplist" | head -1)
if [ -n "$from" ]; then
    fromsnap=${from#*@}
    # NOTE: don't use -F with recv here, since that will prune snapshots from
    # the receiver side (and thus requires destroy permissions there). Instead
    # the receiving dataset should be readonly=on to keep it from getting
    # modified between backups.
    zfs send -R -i "$fromsnap" "$last" | on_target zfs recv -ud "${target}/${pool}" || { 
        echo "E: incremental backup '${last}' failed, cleaning up...'" >&2
        cleanup
    }
else
    echo "W: sending full $last" >&2
    # NOTE: we should *NOT* use recv -F here because it is potentially
    # destructive!
    zfs send -R "$last" | on_target zfs recv -ud "${target}/${pool}" || {
        echo "E: full backup '${last}' failed, cleaning up..." >&2
        cleanup
    }
fi
# Backup success, create new holds and release possible old ones. We
# already have a hold on the local side, need to create one on the remote
# side
on_target "zfs hold -r $HOLD_TAG '${target}/${last}' && [ -n '$from' ] && zfs release -r $HOLD_TAG '$from'" || true
if [ -n "$from" ]; then
    zfs release -r $HOLD_TAG "${dataset}@${fromsnap}" || echo "local release of ${dataset}@${fromsnap} failed" >&2
fi

trap '' INT TERM HUP
